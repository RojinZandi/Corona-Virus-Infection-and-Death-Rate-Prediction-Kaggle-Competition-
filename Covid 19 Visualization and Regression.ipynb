{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/covid19-global-forecasting-week-5/train.csv\n/kaggle/input/covid19-global-forecasting-week-5/submission.csv\n/kaggle/input/covid19-global-forecasting-week-5/test.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import scale\nimport sklearn.linear_model as skl_lm\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom sklearn.preprocessing import scale\nfrom sklearn.feature_selection import RFE\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\n\n#Libraries to import\n\nimport datetime as dt\nimport requests\nimport sys\nfrom itertools import chain\nimport plotly_express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance, plot_tree\n# %load ../standard_import.txt\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import scale\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\nfrom scipy.cluster import hierarchy\n\n%matplotlib inline\nplt.style.use('seaborn-white')\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-5/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-5/test.csv\")\n\ndisplay(train.head())\ndisplay(train.describe())\ntrain.info()\ntrain.isnull().sum()\ntest.isnull().sum()\n\nprint(\"Number of Country_Region: \", train['Country_Region'].nunique())\nprint(\"Dates go from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\nprint(\"Countries with Province/State informed: \", train.loc[train['Province_State']!='None']['Country_Region'].unique())","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"   Id County Province_State Country_Region  Population    Weight        Date  \\\n0   1    NaN            NaN    Afghanistan    27657145  0.058359  2020-01-23   \n1   2    NaN            NaN    Afghanistan    27657145  0.583587  2020-01-23   \n2   3    NaN            NaN    Afghanistan    27657145  0.058359  2020-01-24   \n3   4    NaN            NaN    Afghanistan    27657145  0.583587  2020-01-24   \n4   5    NaN            NaN    Afghanistan    27657145  0.058359  2020-01-25   \n\n           Target  TargetValue  \n0  ConfirmedCases          0.0  \n1      Fatalities          0.0  \n2  ConfirmedCases          0.0  \n3      Fatalities          0.0  \n4  ConfirmedCases          0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>County</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Population</th>\n      <th>Weight</th>\n      <th>Date</th>\n      <th>Target</th>\n      <th>TargetValue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>27657145</td>\n      <td>0.058359</td>\n      <td>2020-01-23</td>\n      <td>ConfirmedCases</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>27657145</td>\n      <td>0.583587</td>\n      <td>2020-01-23</td>\n      <td>Fatalities</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>27657145</td>\n      <td>0.058359</td>\n      <td>2020-01-24</td>\n      <td>ConfirmedCases</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>27657145</td>\n      <td>0.583587</td>\n      <td>2020-01-24</td>\n      <td>Fatalities</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>27657145</td>\n      <td>0.058359</td>\n      <td>2020-01-25</td>\n      <td>ConfirmedCases</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                  Id    Population         Weight    TargetValue\ncount  796490.000000  7.964900e+05  796490.000000  796490.000000\nmean   484795.500000  2.720127e+06       0.530870      10.322858\nstd    279911.129429  3.477771e+07       0.451909     268.106578\nmin         1.000000  8.600000e+01       0.047491  -10034.000000\n25%    242373.250000  1.213300e+04       0.096838       0.000000\n50%    484795.500000  3.053100e+04       0.349413       0.000000\n75%    727217.750000  1.056120e+05       0.968379       0.000000\nmax    969590.000000  1.395773e+09       2.239186   36163.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Population</th>\n      <th>Weight</th>\n      <th>TargetValue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>796490.000000</td>\n      <td>7.964900e+05</td>\n      <td>796490.000000</td>\n      <td>796490.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>484795.500000</td>\n      <td>2.720127e+06</td>\n      <td>0.530870</td>\n      <td>10.322858</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>279911.129429</td>\n      <td>3.477771e+07</td>\n      <td>0.451909</td>\n      <td>268.106578</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>8.600000e+01</td>\n      <td>0.047491</td>\n      <td>-10034.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>242373.250000</td>\n      <td>1.213300e+04</td>\n      <td>0.096838</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>484795.500000</td>\n      <td>3.053100e+04</td>\n      <td>0.349413</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>727217.750000</td>\n      <td>1.056120e+05</td>\n      <td>0.968379</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>969590.000000</td>\n      <td>1.395773e+09</td>\n      <td>2.239186</td>\n      <td>36163.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 796490 entries, 0 to 796489\nData columns (total 9 columns):\n #   Column          Non-Null Count   Dtype  \n---  ------          --------------   -----  \n 0   Id              796490 non-null  int64  \n 1   County          722890 non-null  object \n 2   Province_State  753480 non-null  object \n 3   Country_Region  796490 non-null  object \n 4   Population      796490 non-null  int64  \n 5   Weight          796490 non-null  float64\n 6   Date            796490 non-null  object \n 7   Target          796490 non-null  object \n 8   TargetValue     796490 non-null  float64\ndtypes: float64(2), int64(2), object(5)\nmemory usage: 54.7+ MB\nNumber of Country_Region:  187\nDates go from day 2020-05-16 to day 2020-01-23 , a total of 115 days\nCountries with Province/State informed:  ['Afghanistan' 'Albania' 'Algeria' 'Andorra' 'Angola'\n 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Australia' 'Austria'\n 'Azerbaijan' 'Bahamas' 'Bahrain' 'Bangladesh' 'Barbados' 'Belarus'\n 'Belgium' 'Belize' 'Benin' 'Bhutan' 'Bolivia' 'Bosnia and Herzegovina'\n 'Botswana' 'Brazil' 'Brunei' 'Bulgaria' 'Burkina Faso' 'Burma' 'Burundi'\n 'Cabo Verde' 'Cambodia' 'Cameroon' 'Canada' 'Central African Republic'\n 'Chad' 'Chile' 'China' 'Colombia' 'Comoros' 'Congo (Brazzaville)'\n 'Congo (Kinshasa)' 'Costa Rica' \"Cote d'Ivoire\" 'Croatia' 'Cuba' 'Cyprus'\n 'Czechia' 'Denmark' 'Diamond Princess' 'Djibouti' 'Dominica'\n 'Dominican Republic' 'Ecuador' 'Egypt' 'El Salvador' 'Equatorial Guinea'\n 'Eritrea' 'Estonia' 'Eswatini' 'Ethiopia' 'Fiji' 'Finland' 'France'\n 'Gabon' 'Gambia' 'Georgia' 'Germany' 'Ghana' 'Greece' 'Grenada'\n 'Guatemala' 'Guinea' 'Guinea-Bissau' 'Guyana' 'Haiti' 'Holy See'\n 'Honduras' 'Hungary' 'Iceland' 'India' 'Indonesia' 'Iran' 'Iraq'\n 'Ireland' 'Israel' 'Italy' 'Jamaica' 'Japan' 'Jordan' 'Kazakhstan'\n 'Kenya' 'Korea, South' 'Kosovo' 'Kuwait' 'Kyrgyzstan' 'Laos' 'Latvia'\n 'Lebanon' 'Liberia' 'Libya' 'Liechtenstein' 'Lithuania' 'Luxembourg'\n 'MS Zaandam' 'Madagascar' 'Malawi' 'Malaysia' 'Maldives' 'Mali' 'Malta'\n 'Mauritania' 'Mauritius' 'Mexico' 'Moldova' 'Monaco' 'Mongolia'\n 'Montenegro' 'Morocco' 'Mozambique' 'Namibia' 'Nepal' 'Netherlands'\n 'New Zealand' 'Nicaragua' 'Niger' 'Nigeria' 'North Macedonia' 'Norway'\n 'Oman' 'Pakistan' 'Panama' 'Papua New Guinea' 'Paraguay' 'Peru'\n 'Philippines' 'Poland' 'Portugal' 'Qatar' 'Romania' 'Russia' 'Rwanda'\n 'Saint Kitts and Nevis' 'Saint Lucia' 'Saint Vincent and the Grenadines'\n 'San Marino' 'Sao Tome and Principe' 'Saudi Arabia' 'Senegal' 'Serbia'\n 'Seychelles' 'Sierra Leone' 'Singapore' 'Slovakia' 'Slovenia' 'Somalia'\n 'South Africa' 'South Sudan' 'Spain' 'Sri Lanka' 'Sudan' 'Suriname'\n 'Sweden' 'Switzerland' 'Syria' 'Taiwan*' 'Tajikistan' 'Tanzania'\n 'Thailand' 'Timor-Leste' 'Togo' 'Trinidad and Tobago' 'Tunisia' 'Turkey'\n 'US' 'Uganda' 'Ukraine' 'United Arab Emirates' 'United Kingdom' 'Uruguay'\n 'Uzbekistan' 'Venezuela' 'Vietnam' 'West Bank and Gaza' 'Western Sahara'\n 'Yemen' 'Zambia' 'Zimbabwe']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"ForecastId            0\nCounty            28800\nProvince_State    16830\nCountry_Region        0\nPopulation            0\nWeight                0\nDate                  0\nTarget                0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ID=train['Id']\nFID=test['ForecastId']","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_date_min = train['Date'].min()\ntrain_date_max = train['Date'].max()\nprint('Minimum date from training set: {}'.format(train_date_min))\nprint('Maximum date from training set: {}'.format(train_date_max))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_date_min = test['Date'].min()\ntest_date_max = test['Date'].max()\nprint('Minimum date from test set: {}'.format(test_date_min))\nprint('Maximum date from test set: {}'.format(test_date_max))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ** **Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(train, values='TargetValue', names='Target')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(train, values='TargetValue', names='Country_Region')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(train, values='Population', names='Country_Region')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Feature Selection**"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train.corr()     #computing correlation between features and output\nprint(corr_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Modeling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(columns=['County','Province_State','Id'])\ntest=test.drop(columns=['County','Province_State','ForecastId'])","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"da= pd.to_datetime(train['Date'], errors='coerce')\ntrain['Date']= da.dt.strftime(\"%Y%m%d\").astype(int)\nda= pd.to_datetime(test['Date'], errors='coerce')\ntest['Date']= da.dt.strftime(\"%Y%m%d\").astype(int)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nl = LabelEncoder()\nX = train.iloc[:,0].values\ntrain.iloc[:,0] = l.fit_transform(X.astype(str))\n\nX = train.iloc[:,4].values\ntrain.iloc[:,4] = l.fit_transform(X)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nl = LabelEncoder()\nX = test.iloc[:,0].values\ntest.iloc[:,0] = l.fit_transform(X.astype(str))\n\nX = test.iloc[:,4].values\ntest.iloc[:,4] = l.fit_transform(X)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=train['TargetValue']\nx_train=train.drop(['TargetValue'],axis=1)\n\nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=0)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin_reg=LinearRegression()\nlin_reg.fit(x_train,y_train)\n\nprint(lin_reg.intercept_)\nprint(lin_reg.coef_)","execution_count":15,"outputs":[{"output_type":"stream","text":"-1539337.2549684753\n[-2.35332126e-02  1.06061127e-06  4.02298059e+00  7.62044882e-02\n -2.19615459e+01]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc1=lin_reg.score(x_test,y_test)\nacc1","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"0.019624366611508348"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Linear Regression performs poorly."},{"metadata":{},"cell_type":"markdown","source":"Polynomial Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npoly_reg2=PolynomialFeatures(degree=2)\nx_poly=poly_reg2.fit_transform(x_train)\nlin_reg_2=LinearRegression()\nlin_reg_2.fit(x_poly,y_train)\n\nprint(\"Coefficients of polynimial(degree2) are\", lin_reg_2.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing estimators\nfrom sklearn.ensemble import RandomForestRegressor \nmodel = RandomForestRegressor(n_jobs=-1)\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(x_train, y_train)\n    scores.append(model.score(x_test, y_test))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\np = Pipeline([('scaler2' , StandardScaler()),\n                        ('RandomForestRegressor: ', RandomForestRegressor())])\np.fit(x_train , y_train)\nprediction = p.predict(x_test)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc2=p.score(x_test,y_test)\nacc2","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"0.9311796501254642"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\np.r2_score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create new a knn model\nRFCnew = RandomForestRegressor()\n#create a dictionary of all values we want to test for n_neighbors\nparam_grid = {'max_depth': np.arange(1, 25)}\n#use gridsearch to test all values for n_neighbors\nRFCnew_gscv = GridSearchCV(RFCnew, param_grid, cv=5)\n#fit model to data\nRFCnew_gscv.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The performance of the model is well."},{"metadata":{"trusted":true},"cell_type":"code","source":"predict=p.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output=pd.DataFrame({'id':FID,'TargetValue':predict})\noutput","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=output.groupby(['id'])['TargetValue'].quantile(q=0.05).reset_index()\nb=output.groupby(['id'])['TargetValue'].quantile(q=0.5).reset_index()\nc=output.groupby(['id'])['TargetValue'].quantile(q=0.95).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a.columns=['Id','q0.05']\nb.columns=['Id','q0.5']\nc.columns=['Id','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05']\na['q0.5']=a['q0.5']\na['q0.95']=a['q0.95']\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.melt(a, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}